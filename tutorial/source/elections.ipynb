{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a US presidential election using Bayesian optimal polling\n",
    "\n",
    "In this tutorial, we explore the use of optimal experimental design techniques to create an optimal polling strategy to predict the outcome of the US presidential election. We take the 2012 election as our prior and the 2016 election as our test set: we imagine that we are conducting polling just before the 2016 election.\n",
    "\n",
    "## The model\n",
    "For each of the 50 states we define \n",
    "\n",
    "$$ \\text{logit }\\mathbb{P}(\\text{a random voter in state } i \\text{ votes Democrat in the 2016 election}) = \\theta_i $$\n",
    "\n",
    "and we assume all other voters vote Republican. Right before the election, the value of $\\theta$ is unknown and we wish to estimate it using polling. The winner $w$ of the election is decided by the Electoral College system. The number of electoral college votes gained by the Democrats in state $i$ is\n",
    "$$\n",
    "e_i =  \\begin{cases}\n",
    "k_i \\text{ if } \\theta_i > \\frac{1}{2} \\\\\n",
    "0 \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "(this is a rough approximation of the true system). All other electoral college votes go to the Republicans. Here $k_i$ is the number of electoral college votes alloted to state $i$, which are listed in the following data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Electoral college votes\n",
      "State                         \n",
      "AL                           9\n",
      "AK                           3\n",
      "AZ                          11\n",
      "AR                           6\n",
      "CA                          55\n",
      "CO                           9\n",
      "CT                           7\n",
      "DE                           3\n",
      "DC                           3\n",
      "FL                          29\n",
      "GA                          16\n",
      "HI                           4\n",
      "ID                           4\n",
      "IL                          20\n",
      "IN                          11\n",
      "IA                           6\n",
      "KS                           6\n",
      "KY                           8\n",
      "LA                           8\n",
      "ME                           4\n",
      "MD                          10\n",
      "MA                          11\n",
      "MI                          16\n",
      "MN                          10\n",
      "MS                           6\n",
      "MO                          10\n",
      "MT                           3\n",
      "NE                           5\n",
      "NV                           6\n",
      "NH                           4\n",
      "NJ                          14\n",
      "NM                           5\n",
      "NY                          29\n",
      "NC                          15\n",
      "ND                           3\n",
      "OH                          18\n",
      "OK                           7\n",
      "OR                           7\n",
      "PA                          20\n",
      "RI                           4\n",
      "SC                           9\n",
      "SD                           3\n",
      "TN                          11\n",
      "TX                          38\n",
      "UT                           6\n",
      "VT                           3\n",
      "VA                          13\n",
      "WA                          12\n",
      "WV                           5\n",
      "WI                          10\n",
      "WY                           3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "electoral_college_votes = pd.read_pickle(\"electoral_college_votes.pickle\")\n",
    "print(electoral_college_votes)\n",
    "ec_votes_tensor = torch.tensor(electoral_college_votes.values, dtype=torch.float).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner $w$ of the election is\n",
    "\n",
    "$$ w = \\begin{cases}\n",
    "\\text{Democrats if } \\sum_i e_i > \\frac{1}{2}\\sum_i k_i  \\\\\n",
    "\\text{Republicans otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in polling strategies that will help us predict $w$, rather than predicting the more complex state-by-state results $\\theta$.\n",
    "\n",
    "To set up a fully Bayesian model, we need a prior for $\\theta$. We will base the prior on the outcome of some historical presidential elections. Specifically, we'll use the following dataset of state-by-state election results for the presidential elections 1996-2012 inclusive. Note that votes for parties other than Democrats and Republicans have been ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1996                2000                2004                2008  \\\n",
      "      Democrat Republican Democrat Republican Democrat Republican Democrat   \n",
      "State                                                                        \n",
      "AL      662165     769044   692611     941173   693933    1176394   813479   \n",
      "AK       80380     122746    79004     167398   111025     190889   123594   \n",
      "AZ      653288     622073   685341     781652   893524    1104294  1034707   \n",
      "AR      475171     325416   422768     472940   469953     572898   422310   \n",
      "CA     5119835    3828380  5861203    4567429  6745485    5509826  8274473   \n",
      "CO      671152     691848   738227     883748  1001732    1101255  1288633   \n",
      "CT      735740     483109   816015     561094   857488     693826   997772   \n",
      "DE      140355      99062   180068     137288   200152     171660   255459   \n",
      "DC      158220      17339   171923      18073   202970      21256   245800   \n",
      "FL     2546870    2244536  2912253    2912790  3583544    3964522  4282074   \n",
      "GA     1053849    1080843  1116230    1419720  1366149    1914254  1844123   \n",
      "HI      205012     113943   205286     137845   231708     194191   325871   \n",
      "ID      165443     256595   138637     336937   181098     409235   236440   \n",
      "IL     2341744    1587021  2589026    2019421  2891550    2345946  3419348   \n",
      "IN      887424    1006693   901980    1245836   969011    1479438  1374039   \n",
      "IA      620258     492644   638517     634373   741898     751957   828940   \n",
      "KS      387659     583245   399276     622332   434993     736456   514765   \n",
      "KY      636614     623283   638898     872492   712733    1069439   751985   \n",
      "LA      927837     712586   792344     927871   820299    1102169   782989   \n",
      "ME      312788     186378   319951     286616   396842     330201   421923   \n",
      "MD      966207     681530  1145782     813797  1334493    1024703  1629467   \n",
      "MA     1571763     718107  1616487     878502  1803800    1071109  1904097   \n",
      "MI     1989653    1481212  2170418    1953139  2479183    2313746  2872579   \n",
      "MN     1120438     766476  1168266    1109659  1445014    1346695  1573354   \n",
      "MS      394022     439838   404614     572844   458094     684981   554662   \n",
      "MO     1025935     890016  1111138    1189924  1259171    1455713  1441911   \n",
      "MT      167922     179652   137126     240178   173710     266063   231667   \n",
      "NE      236761     363467   231780     433862   254328     512814   333319   \n",
      "NV      203974     199244   279978     301575   397190     418690   533736   \n",
      "NH      246214     196532   266348     273559   340511     331237   384826   \n",
      "NJ     1652329    1103078  1788850    1284173  1911430    1670003  2215422   \n",
      "NM      273495     232751   286783     286417   370942     376930   472422   \n",
      "NY     3756177    1933492  4107697    2403374  4314280    2962567  4804945   \n",
      "NC     1107849    1225938  1257692    1631163  1525849    1961166  2142651   \n",
      "ND      106905     125050    95284     174852   111052     196651   141278   \n",
      "OH     2148222    1859883  2186190    2351209  2741167    2859768  2940044   \n",
      "OK      488105     582315   474276     744337   503966     959792   502496   \n",
      "OR      649641     538152   720342     713577   943163     866831  1037291   \n",
      "PA     2215819    1801169  2485967    2281127  2938095    2793847  3276363   \n",
      "RI      233050     104683   249508     130555   259765     169046   296571   \n",
      "SC      504051     573458   565561     785937   661699     937974   862449   \n",
      "SD      139333     150543   118804     190700   149244     232584   170924   \n",
      "TN      909146     863530   981720    1061949  1036477    1384375  1087437   \n",
      "TX     2459683    2736167  2433746    3799639  2832704    4526917  3528633   \n",
      "UT      221633     361911   203053     515096   241199     663742   327670   \n",
      "VT      137894      80352   149022     119775   184067     121180   219262   \n",
      "VA     1091060    1138350  1217290    1437490  1454742    1716959  1959532   \n",
      "WA     1123323     840712  1247652    1108864  1510201    1304894  1750848   \n",
      "WV      327812     233946   295497     336475   326541     423778   303857   \n",
      "WI     1071971     845029  1242987    1237279  1489504    1478120  1677211   \n",
      "WY       77934     105388    60481     147947    70776     167629    82868   \n",
      "\n",
      "                     2012             \n",
      "      Republican Democrat Republican  \n",
      "State                                 \n",
      "AL       1266546   795696    1255925  \n",
      "AK        193841   122640     164676  \n",
      "AZ       1230111  1025232    1233654  \n",
      "AR        638017   394409     647744  \n",
      "CA       5011781  7854285    4839958  \n",
      "CO       1073629  1323101    1185243  \n",
      "CT        629428   905083     634892  \n",
      "DE        152374   242584     165484  \n",
      "DC         17367   267070      21381  \n",
      "FL       4045624  4237756    4163447  \n",
      "GA       2048759  1773827    2078688  \n",
      "HI        120566   306658     121015  \n",
      "ID        403012   212787     420911  \n",
      "IL       2031179  3019512    2135216  \n",
      "IN       1345648  1152887    1420543  \n",
      "IA        682379   822544     730617  \n",
      "KS        699655   440726     692634  \n",
      "KY       1048462   679370    1087190  \n",
      "LA       1148275   809141    1152262  \n",
      "ME        295273   401306     292276  \n",
      "MD        959862  1677844     971869  \n",
      "MA       1108854  1921290    1188314  \n",
      "MI       2048639  2564569    2115256  \n",
      "MN       1275409  1546167    1320225  \n",
      "MS        724597   562949     710746  \n",
      "MO       1445814  1223796    1482440  \n",
      "MT        242763   201839     267928  \n",
      "NE        452979   302081     475064  \n",
      "NV        412827   531373     463567  \n",
      "NH        316534   369561     329918  \n",
      "NJ       1613207  2125101    1477568  \n",
      "NM        346832   415335     335788  \n",
      "NY       2752771  4485741    2490431  \n",
      "NC       2128474  2178391    2270395  \n",
      "ND        168601   124827     188163  \n",
      "OH       2677820  2827709    2661437  \n",
      "OK        960165   443547     891325  \n",
      "OR        738475   970488     754175  \n",
      "PA       2655885  2990274    2680434  \n",
      "RI        165391   279677     157204  \n",
      "SC       1034896   865941    1071645  \n",
      "SD        203054   145039     210610  \n",
      "TN       1479178   960709    1462330  \n",
      "TX       4479328  3308124    4569843  \n",
      "UT        596030   251813     740600  \n",
      "VT         98974   199239      92698  \n",
      "VA       1725005  1971820    1822522  \n",
      "WA       1229216  1755396    1290670  \n",
      "WV        397466   238269     417655  \n",
      "WI       1262393  1620985    1407966  \n",
      "WY        164958    69286     170962  \n"
     ]
    }
   ],
   "source": [
    "frame = pd.read_pickle(\"us_presidential_election_data_1996_to_2012.pickle\")\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this data alone, we will base our prior mean for $\\theta$ solely on the 2012 election. Specifically, we'll choose a prior mean as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4564, -0.2947, -0.1851, -0.4961,  0.4842,  0.1100,  0.3546,  0.3825,\n",
      "         2.5250,  0.0177, -0.1586,  0.9298, -0.6821,  0.3465, -0.2088,  0.1185,\n",
      "        -0.4521, -0.4702, -0.3535,  0.3170,  0.5460,  0.4805,  0.1926,  0.1580,\n",
      "        -0.2331, -0.1917, -0.2832, -0.4528,  0.1365,  0.1135,  0.3634,  0.2126,\n",
      "         0.5884, -0.0414, -0.4104,  0.0606, -0.6979,  0.2522,  0.1094,  0.5761,\n",
      "        -0.2131, -0.3730, -0.4201, -0.3231, -1.0788,  0.7652,  0.0787,  0.3075,\n",
      "        -0.5613,  0.1409, -0.9032])\n"
     ]
    }
   ],
   "source": [
    "results_2012 = torch.tensor(frame[2012].values, dtype=torch.float)\n",
    "prior_mean = torch.log(results_2012[..., 0] / results_2012[..., 1])\n",
    "print(prior_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prior distribution for $\\theta$ will be a multivariate Normal with mean `prior_mean`. The only thing left to decide upon is the covariance matrix.\n",
    "\n",
    "*Aside*: The prior covariance is important in a number of ways. If we allow too much variance, the prior will be uncertain about the outcome in every state, and require polling everywhere. If we allow too little variance, we may be caught off-guard by an unexpected electoral outcome. If we assume states are independent, then we will not be able to pool information across states; but assume too much correlation and we could too faithfully base predictions about one state from poll results in another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the prior covariance by taking the empirical covariance from the elections 1996 - 2012 and adding a small value `0.01` to the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.tensor([0, 2, 4, 6, 8])\n",
    "as_tensor = torch.tensor(frame.values, dtype=torch.float)\n",
    "logits = torch.log(as_tensor[..., idx] / as_tensor[..., idx + 1]).transpose(0, 1)\n",
    "mean = logits.mean(0)\n",
    "sample_covariance = (1/(logits.shape[0] - 1)) * (\n",
    "    (logits.unsqueeze(-1) - mean) * (logits.unsqueeze(-2) - mean)\n",
    ").sum(0)\n",
    "prior_covariance = sample_covariance + 0.01 * torch.eye(sample_covariance.shape[0])\n",
    "prior_scale_tril = prior_covariance.cholesky()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a position to define our Bayesian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.util import iter_plates_to_shape\n",
    "\n",
    "def model(polling_allocation):\n",
    "    with ExitStack() as stack:\n",
    "        for plate in iter_plates_to_shape(polling_allocation.shape[:-1]):\n",
    "            stack.enter_context(plate)\n",
    "        theta = pyro.sample(\"theta\", dist.MultivariateNormal(prior_mean, scale_tril=prior_scale_tril))\n",
    "        poll_results = pyro.sample(\"y\", dist.Binomial(polling_allocation, logits=theta).to_event(1))\n",
    "        dem_win_state = (theta > 0.).float()\n",
    "        dem_electoral_college_votes = ec_votes_tensor * dem_win_state\n",
    "        dem_win = dem_electoral_college_votes.sum(-1) / ec_votes_tensor.sum(-1) > .5\n",
    "        pyro.sample(\"w\", dist.Delta(dem_win))\n",
    "        return poll_results, dem_win, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Bayesian model implicitly defines our prior on `w`. We can investigate this prior by simulating many times from our prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability of Dem win 0.7882400155067444\n"
     ]
    }
   ],
   "source": [
    "_, dem_wins, theta = model(torch.ones(100000, 51))\n",
    "print(\"Prior probability of Dem win\", dem_wins.float().mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also investigate which states, a priori, are most marginal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Democrat win probability\n",
      "State                          \n",
      "FL                      0.55407\n",
      "NC                      0.39687\n",
      "OH                      0.67355\n",
      "VA                      0.67953\n",
      "CO                      0.73171\n",
      "NH                      0.78041\n",
      "IA                      0.78863\n",
      "NV                      0.78917\n",
      "WI                      0.80645\n",
      "PA                      0.81251\n",
      "MN                      0.83032\n",
      "GA                      0.15569\n",
      "IN                      0.14710\n",
      "MT                      0.12369\n",
      "MO                      0.12050\n",
      "NM                      0.89127\n",
      "LA                      0.10633\n",
      "MI                      0.89658\n",
      "AZ                      0.10004\n",
      "AR                      0.08153\n",
      "AK                      0.06664\n",
      "OR                      0.93732\n",
      "SC                      0.06216\n",
      "MS                      0.06205\n",
      "WV                      0.05106\n",
      "ME                      0.95679\n",
      "ND                      0.04038\n",
      "TX                      0.03695\n",
      "SD                      0.03077\n",
      "TN                      0.02557\n",
      "WA                      0.98374\n",
      "KY                      0.01408\n",
      "IL                      0.98632\n",
      "DE                      0.98882\n",
      "NE                      0.00861\n",
      "NJ                      0.99427\n",
      "AL                      0.00535\n",
      "HI                      0.99513\n",
      "CT                      0.99519\n",
      "CA                      0.99781\n",
      "VT                      0.99837\n",
      "OK                      0.00137\n",
      "MA                      0.99901\n",
      "ID                      0.00059\n",
      "WY                      0.00043\n",
      "MD                      0.99967\n",
      "KS                      0.00028\n",
      "RI                      0.99977\n",
      "UT                      0.00005\n",
      "NY                      0.99997\n",
      "DC                      1.00000\n"
     ]
    }
   ],
   "source": [
    "dem_prob = (theta > 0.).float().mean(0)\n",
    "marginal = torch.argsort((dem_prob - .5).abs()).numpy()\n",
    "prior_prob_dem = pd.DataFrame({\"State\": frame.index[marginal],\n",
    "                               \"Democrat win probability\": dem_prob.numpy()[marginal]}).set_index('State')\n",
    "print(prior_prob_dem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a sanity check, and seems to accord with our intuitions. Since our prior is based on 2012 and the Democrats won in 2012, it makes sense that we would favour a Democrat win in 2016 (this is before we have seen *any* polling data or incorporated any other information). Florida is frequently an important swing state and is top of our list of marginal states under the prior. We can also see states such as Pennsylvania and Wisconsin near the top of the list -- we know that these were instrumental in the 2016 election. (This kind of posthoc analysis is, of course, very bad and only engaged in by immoral persons.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional correlations\n",
    "\n",
    "Finally, we take a closer look at our prior covariance. Specifically, we examine states that we expect to be more or less correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State        ME        VT        NH        MA        RI        CT\n",
      "State                                                            \n",
      "ME     1.000000  0.477886  0.596116  0.356695  0.423679  0.323017\n",
      "VT     0.477886  1.000000  0.499662 -0.215523 -0.024518  0.261711\n",
      "NH     0.596116  0.499661  1.000000  0.225995  0.298397  0.319969\n",
      "MA     0.356695 -0.215523  0.225995  1.000000  0.527190  0.208689\n",
      "RI     0.423679 -0.024518  0.298397  0.527190  1.000000  0.395217\n",
      "CT     0.323017  0.261710  0.319969  0.208689  0.395216  1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def correlation(cov):\n",
    "    return cov / np.sqrt(np.expand_dims(np.diag(cov.values), 0) * np.expand_dims(np.diag(cov.values), 1))\n",
    "                \n",
    "\n",
    "new_england_states = ['ME', 'VT', 'NH', 'MA', 'RI', 'CT']\n",
    "cov_as_frame = pd.DataFrame(prior_covariance.numpy(), columns=frame.index).set_index(frame.index)\n",
    "ne_cov = cov_as_frame.loc[new_england_states, new_england_states]\n",
    "ne_corr = correlation(ne_cov)\n",
    "print(ne_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State        CA        OR        WA\n",
      "State                              \n",
      "CA     1.000000  0.573579  0.502279\n",
      "OR     0.573579  1.000000  0.558791\n",
      "WA     0.502279  0.558791  1.000000\n"
     ]
    }
   ],
   "source": [
    "pacific_states = ['CA', 'OR', 'WA']\n",
    "pacific_cov = cov_as_frame.loc[pacific_states, pacific_states]\n",
    "pacific_corr = correlation(pacific_cov)\n",
    "print(pacific_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These correlation matrices show that, as expected, logical groupings of states tend to have similar voting trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State        CA        OR        WA\n",
      "State                              \n",
      "ME     0.267481  0.449183  0.485293\n",
      "VT     0.669012  0.716531  0.626596\n",
      "NH     0.323909  0.474809  0.473340\n",
      "MA    -0.240504 -0.107660  0.007864\n",
      "RI     0.026399  0.051822  0.171505\n",
      "CT     0.334647  0.307990  0.328485\n"
     ]
    }
   ],
   "source": [
    "cross_cov = cov_as_frame.loc[new_england_states + pacific_states, new_england_states + pacific_states]\n",
    "cross_corr = correlation(cross_cov)\n",
    "print(cross_corr.loc[new_england_states, pacific_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f4318967c18>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = (logits - mean)[...,0:2].numpy()\n",
    "x, y = data[..., 0], data[..., 1]\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these values appear spurious, perhaps we need to more carefully set our covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-4fd0aa0c0002>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-4fd0aa0c0002>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    def forward(self, )\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class OutcomePredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(51, 256)\n",
    "        self.lin2 = nn.Linear(256, 256)\n",
    "        self.lin3 = nn.Linear(256, 1)\n",
    "        \n",
    "    def compute_dem_probability(self, y):\n",
    "        y = F.relu(self.lin1(y))\n",
    "        y = F.relu(self.lin2(y))\n",
    "        return self.lin3(y)\n",
    "    \n",
    "    def forward(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
